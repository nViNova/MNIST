{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbPuRoSpZ-_z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, v2, InterpolationMode\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JCqw9mT_Wdk1"
      },
      "outputs": [],
      "source": [
        "classes = [str(x) for x in range(10)] # A list of class names in str for the dataset. (Digits 0 - 9)\n",
        "\n",
        "# preprocessing\n",
        "# chose a random rotation and perspective transformation to add more variety and samples to the dataset.\n",
        "# opted to have a random rotation of 45 degrees as to not 'mix' digits 6 and 9.\n",
        "# opted not to add flips as the inverted digits are invalid.\n",
        "transforms = v2.Compose([\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.RandomRotation(degrees=45),\n",
        "    v2.RandomPerspective()\n",
        "])\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=v2.Compose([\n",
        "        v2.PILToTensor(),\n",
        "        v2.ToDtype(torch.float32, scale=True)\n",
        "    ])\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show a 3 x 3 grid of random samples from the training data\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(classes[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(v2.ToPILImage()( img), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show a 3 x 3 grid of random samples from the test data\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(test_data), size=(1,)).item()\n",
        "    img, label = test_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(classes[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(v2.ToPILImage()( img), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbjAbJEldji5",
        "outputId": "bdfa70e0-3d0a-45e0-c4f2-c7abc59626f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Batch size based from PyTorch Docs\n",
        "batch_size = 128\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\") # images of digits\n",
        "    #             (N) Batch Size, (C)hannels, (H)eight, (W)idth\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\") # labels of image\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAqHW7ttW-M2",
        "outputId": "acc00c58-159f-46eb-ccd6-16fa0c044e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "# nn obtained from trial and error\n",
        "from nn import NeuralNetwork\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W-XOYP6rZE0R"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# use adam optimizer for faster convergence (attempted SGD initially)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train() and test() funcs obtained from PyTorch Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FwNcifHBYAyV"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hoaDcKzoYRnk"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zskxc6MYTvU",
        "outputId": "e3ab0e65-3d53-4766-d702-294b705315a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.296270  [   64/60000]\n",
            "loss: 1.638084  [ 6464/60000]\n",
            "loss: 1.594119  [12864/60000]\n",
            "loss: 1.162075  [19264/60000]\n",
            "loss: 1.344553  [25664/60000]\n",
            "loss: 0.909615  [32064/60000]\n",
            "loss: 1.162738  [38464/60000]\n",
            "loss: 0.920452  [44864/60000]\n",
            "loss: 1.149602  [51264/60000]\n",
            "loss: 0.990774  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.6%, Avg loss: 0.369002 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.817834  [   64/60000]\n",
            "loss: 0.763675  [ 6464/60000]\n",
            "loss: 0.575827  [12864/60000]\n",
            "loss: 0.879544  [19264/60000]\n",
            "loss: 0.511142  [25664/60000]\n",
            "loss: 0.584740  [32064/60000]\n",
            "loss: 0.363843  [38464/60000]\n",
            "loss: 0.482345  [44864/60000]\n",
            "loss: 0.569009  [51264/60000]\n",
            "loss: 0.563926  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.256034 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.628371  [   64/60000]\n",
            "loss: 0.726805  [ 6464/60000]\n",
            "loss:     nan  [12864/60000]\n",
            "loss:     nan  [19264/60000]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[8], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction error\u001b[39;49;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\transforms\\v2\\_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\transforms\\v2\\_transform.py:166\u001b[0m, in \u001b[0;36m_RandomApplyTransform.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n\u001b[1;32m--> 166\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_needs_transform_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[0;32m    168\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    171\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[0;32m    174\u001b[0m ]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\transforms\\v2\\_transform.py:57\u001b[0m, in \u001b[0;36mTransform._needs_transform_list\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[0;32m     53\u001b[0m     ]\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_needs_transform_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, flat_inputs: List[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mbool\u001b[39m]:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Below is a heuristic on how to deal with pure tensor inputs:\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# 1. Pure tensors, i.e. tensors that are not a tv_tensor, are passed through if there is an explicit image\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m#    (`tv_tensors.Image` or `PIL.Image.Image`) or video (`tv_tensors.Video`) in the sample.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# 2. If there is no explicit image or video in the sample, only the first encountered pure tensor is\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m#    transformed as image, while the rest is passed through. The order is defined by the returned `flat_inputs`\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m#    of `tree_flatten`, which recurses depth-first through the input.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# This heuristic stems from two requirements:\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# 1. We need to keep BC for single input pure tensors and treat them as images.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# 2. We don't want to treat all pure tensors as images, because some datasets like `CelebA` or `Widerface`\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m#    return supplemental numerical data as tensors that cannot be transformed as images.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# The heuristic should work well for most people in practice. The only case where it doesn't is if someone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# tries to transform multiple pure tensors at the same time, expecting them all to be treated as images.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# However, this case wasn't supported by transforms v1 either, so there is no BC concern.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     needs_transform_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m     transform_pure_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_any(flat_inputs, tv_tensors\u001b[38;5;241m.\u001b[39mImage, tv_tensors\u001b[38;5;241m.\u001b[39mVideo, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# opted for 16 epochs due to model converging at around this amount.\n",
        "epochs = 16\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tpc_edEY-eB",
        "outputId": "24d964e1-dab4-4587-96ec-a8d538f70cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m4WOvKcZOKw",
        "outputId": "41c6b8f0-c765-43b8-8a3a-741068f7972a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qEuSrzq1ZQNR",
        "outputId": "e841be88-b59b-4abb-be7e-a94ee0dd449f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data Len: 10000\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"0\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"1\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"0\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"1\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"1\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"0\"\n",
            "Predicted: \"4\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"0\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"1\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"1\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"0\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"1\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"1\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"0\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"0\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"1\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"1\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"1\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Tests:9531/10000 OK\n"
          ]
        }
      ],
      "source": [
        "# Perform a Quick Test on the Test Dataset\n",
        "\n",
        "model.eval()\n",
        "fail = 0\n",
        "\n",
        "print(\"Test Data Len: \" + str(len(test_data)))\n",
        "\n",
        "for x, y in test_data:\n",
        "  with torch.no_grad():\n",
        "      x = x.to(device)\n",
        "      pred = model(x)\n",
        "      predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "      if(predicted != actual):\n",
        "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "        fail += 1\n",
        "\n",
        "print(\"Tests:\" + str(len(test_data) - fail) + \"/\" + str(len(test_data)) + \" OK\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
