{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbPuRoSpZ-_z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, v2, InterpolationMode\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JCqw9mT_Wdk1"
      },
      "outputs": [],
      "source": [
        "classes = [str(x) for x in range(10)] # A list of class names in str for the dataset. (Digits 0 - 9)\n",
        "\n",
        "# preprocessing\n",
        "# chose a random rotation and light perspective transformation to add more variety and samples to the dataset.\n",
        "# opted to have a random rotation of 45 degrees as to not 'mix' digits 6 and 9.\n",
        "# opted not to add flips as the inverted digits are invalid.\n",
        "transforms = v2.Compose([\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.RandomRotation(degrees=45),\n",
        "    v2.RandomPerspective()\n",
        "])\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show a 3 x 3 grid of random samples from the training data\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(classes[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(v2.ToPILImage()( img), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbjAbJEldji5",
        "outputId": "bdfa70e0-3d0a-45e0-c4f2-c7abc59626f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "# Batch size based from PyTorch Docs\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\") # images of digits\n",
        "    #             (N) Batch Size, (C)hannels, (H)eight, (W)idth\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\") # labels of image\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAqHW7ttW-M2",
        "outputId": "acc00c58-159f-46eb-ccd6-16fa0c044e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "# nn obtained from trial and error\n",
        "from nn import NeuralNetwork\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W-XOYP6rZE0R"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# use adam optimizer for faster convergence (attempted SGD initially)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "train() and test() funcs obtained from PyTorch Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FwNcifHBYAyV"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hoaDcKzoYRnk"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zskxc6MYTvU",
        "outputId": "e3ab0e65-3d53-4766-d702-294b705315a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.298551  [   64/60000]\n",
            "loss: 1.151273  [ 6464/60000]\n",
            "loss: 1.179418  [12864/60000]\n",
            "loss: 0.734627  [19264/60000]\n",
            "loss: 0.810110  [25664/60000]\n",
            "loss: 0.579449  [32064/60000]\n",
            "loss: 0.567100  [38464/60000]\n",
            "loss: 0.586513  [44864/60000]\n",
            "loss: 0.539349  [51264/60000]\n",
            "loss: 0.481859  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.486282 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.428576  [   64/60000]\n",
            "loss: 0.544491  [ 6464/60000]\n",
            "loss: 0.439557  [12864/60000]\n",
            "loss: 0.358950  [19264/60000]\n",
            "loss: 0.716368  [25664/60000]\n",
            "loss: 0.442831  [32064/60000]\n",
            "loss: 0.437766  [38464/60000]\n",
            "loss: 0.246961  [44864/60000]\n",
            "loss: 0.453767  [51264/60000]\n",
            "loss: 0.283924  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.349807 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.291766  [   64/60000]\n",
            "loss: 0.168323  [ 6464/60000]\n",
            "loss: 0.469706  [12864/60000]\n",
            "loss: 0.291758  [19264/60000]\n",
            "loss: 0.360816  [25664/60000]\n",
            "loss: 0.344710  [32064/60000]\n",
            "loss: 0.335512  [38464/60000]\n",
            "loss: 0.194864  [44864/60000]\n",
            "loss: 0.318847  [51264/60000]\n",
            "loss: 0.284996  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.290503 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.351034  [   64/60000]\n",
            "loss: 0.374162  [ 6464/60000]\n",
            "loss: 0.270689  [12864/60000]\n",
            "loss: 0.631152  [19264/60000]\n",
            "loss: 0.379295  [25664/60000]\n",
            "loss: 0.308970  [32064/60000]\n",
            "loss: 0.430340  [38464/60000]\n",
            "loss: 0.443924  [44864/60000]\n",
            "loss: 0.138752  [51264/60000]\n",
            "loss: 0.144412  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.267117 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.192176  [   64/60000]\n",
            "loss: 0.108869  [ 6464/60000]\n",
            "loss: 0.348266  [12864/60000]\n",
            "loss: 0.200856  [19264/60000]\n",
            "loss: 0.351748  [25664/60000]\n",
            "loss: 0.172938  [32064/60000]\n",
            "loss: 0.212132  [38464/60000]\n",
            "loss: 0.461074  [44864/60000]\n",
            "loss: 0.214176  [51264/60000]\n",
            "loss: 0.548290  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.9%, Avg loss: 0.231254 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.128454  [   64/60000]\n",
            "loss: 0.195693  [ 6464/60000]\n",
            "loss: 0.381539  [12864/60000]\n",
            "loss: 0.270761  [19264/60000]\n",
            "loss: 0.196458  [25664/60000]\n",
            "loss: 0.167287  [32064/60000]\n",
            "loss: 0.120252  [38464/60000]\n",
            "loss: 0.226802  [44864/60000]\n",
            "loss: 0.201504  [51264/60000]\n",
            "loss: 0.167168  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.4%, Avg loss: 0.238465 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.078113  [   64/60000]\n",
            "loss: 0.282922  [ 6464/60000]\n",
            "loss: 0.239406  [12864/60000]\n",
            "loss: 0.231565  [19264/60000]\n",
            "loss: 0.325708  [25664/60000]\n",
            "loss: 0.125888  [32064/60000]\n",
            "loss: 0.390669  [38464/60000]\n",
            "loss: 0.146714  [44864/60000]\n",
            "loss: 0.257907  [51264/60000]\n",
            "loss: 0.168871  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.204720 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.063280  [   64/60000]\n",
            "loss: 0.157895  [ 6464/60000]\n",
            "loss: 0.282424  [12864/60000]\n",
            "loss: 0.284091  [19264/60000]\n",
            "loss: 0.264870  [25664/60000]\n",
            "loss: 0.147148  [32064/60000]\n",
            "loss: 0.212221  [38464/60000]\n",
            "loss: 0.091242  [44864/60000]\n",
            "loss: 0.180267  [51264/60000]\n",
            "loss: 0.120935  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.6%, Avg loss: 0.195746 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.226099  [   64/60000]\n",
            "loss: 0.210840  [ 6464/60000]\n",
            "loss: 0.064378  [12864/60000]\n",
            "loss: 0.068971  [19264/60000]\n",
            "loss: 0.245265  [25664/60000]\n",
            "loss: 0.241353  [32064/60000]\n",
            "loss: 0.180963  [38464/60000]\n",
            "loss: 0.320880  [44864/60000]\n",
            "loss: 0.336028  [51264/60000]\n",
            "loss: 0.461941  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.186530 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.276975  [   64/60000]\n",
            "loss: 0.105462  [ 6464/60000]\n",
            "loss: 0.148780  [12864/60000]\n",
            "loss: 0.181714  [19264/60000]\n",
            "loss: 0.154044  [25664/60000]\n",
            "loss: 0.196459  [32064/60000]\n",
            "loss: 0.412587  [38464/60000]\n",
            "loss: 0.074231  [44864/60000]\n",
            "loss: 0.126539  [51264/60000]\n",
            "loss: 0.200114  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.177671 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.101274  [   64/60000]\n",
            "loss: 0.129968  [ 6464/60000]\n",
            "loss: 0.185817  [12864/60000]\n",
            "loss: 0.190105  [19264/60000]\n",
            "loss: 0.180002  [25664/60000]\n",
            "loss: 0.286644  [32064/60000]\n",
            "loss: 0.132765  [38464/60000]\n",
            "loss: 0.120708  [44864/60000]\n",
            "loss: 0.165514  [51264/60000]\n",
            "loss: 0.195125  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.170593 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.208753  [   64/60000]\n",
            "loss: 0.097075  [ 6464/60000]\n",
            "loss: 0.134864  [12864/60000]\n",
            "loss: 0.118648  [19264/60000]\n",
            "loss: 0.251675  [25664/60000]\n",
            "loss: 0.241922  [32064/60000]\n",
            "loss: 0.125459  [38464/60000]\n",
            "loss: 0.242064  [44864/60000]\n",
            "loss: 0.107488  [51264/60000]\n",
            "loss: 0.199378  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.4%, Avg loss: 0.176647 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.101247  [   64/60000]\n",
            "loss: 0.144286  [ 6464/60000]\n",
            "loss: 0.049607  [12864/60000]\n",
            "loss: 0.167226  [19264/60000]\n",
            "loss: 0.118074  [25664/60000]\n",
            "loss: 0.210765  [32064/60000]\n",
            "loss: 0.150258  [38464/60000]\n",
            "loss: 0.169130  [44864/60000]\n",
            "loss: 0.240799  [51264/60000]\n",
            "loss: 0.235969  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.0%, Avg loss: 0.161154 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.110230  [   64/60000]\n",
            "loss: 0.138015  [ 6464/60000]\n",
            "loss: 0.384793  [12864/60000]\n",
            "loss: 0.096372  [19264/60000]\n",
            "loss: 0.173857  [25664/60000]\n",
            "loss: 0.423473  [32064/60000]\n",
            "loss: 0.112897  [38464/60000]\n",
            "loss: 0.093277  [44864/60000]\n",
            "loss: 0.110556  [51264/60000]\n",
            "loss: 0.322038  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.3%, Avg loss: 0.182886 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.206302  [   64/60000]\n",
            "loss: 0.145947  [ 6464/60000]\n",
            "loss: 0.067039  [12864/60000]\n",
            "loss: 0.201912  [19264/60000]\n",
            "loss: 0.321165  [25664/60000]\n",
            "loss: 0.115948  [32064/60000]\n",
            "loss: 0.050157  [38464/60000]\n",
            "loss: 0.109063  [44864/60000]\n",
            "loss: 0.151875  [51264/60000]\n",
            "loss: 0.066196  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.165343 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.191767  [   64/60000]\n",
            "loss: 0.200179  [ 6464/60000]\n",
            "loss: 0.089848  [12864/60000]\n",
            "loss: 0.170596  [19264/60000]\n",
            "loss: 0.043443  [25664/60000]\n",
            "loss: 0.116005  [32064/60000]\n",
            "loss: 0.209201  [38464/60000]\n",
            "loss: 0.186166  [44864/60000]\n",
            "loss: 0.453804  [51264/60000]\n",
            "loss: 0.162385  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.9%, Avg loss: 0.161732 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# opted for 16 epochs due to time constraints in training, and the model converging at this amount.\n",
        "epochs = 16\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tpc_edEY-eB",
        "outputId": "24d964e1-dab4-4587-96ec-a8d538f70cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m4WOvKcZOKw",
        "outputId": "41c6b8f0-c765-43b8-8a3a-741068f7972a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qEuSrzq1ZQNR",
        "outputId": "e841be88-b59b-4abb-be7e-a94ee0dd449f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Data Len: 10000\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"0\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"1\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"0\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"1\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"1\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"0\"\n",
            "Predicted: \"4\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"0\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"1\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"1\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"0\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"1\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"1\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"6\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"0\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"0\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"7\", Actual: \"1\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"1\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"9\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"1\", Actual: \"8\"\n",
            "Predicted: \"0\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"4\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"1\"\n",
            "Predicted: \"1\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"0\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"0\"\n",
            "Predicted: \"0\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"5\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"6\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"1\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"5\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"8\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"4\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"6\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"7\", Actual: \"3\"\n",
            "Predicted: \"3\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"8\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"7\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"7\", Actual: \"4\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"2\", Actual: \"3\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"8\"\n",
            "Predicted: \"3\", Actual: \"5\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"8\", Actual: \"7\"\n",
            "Predicted: \"8\", Actual: \"9\"\n",
            "Predicted: \"4\", Actual: \"9\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"3\", Actual: \"8\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"9\"\n",
            "Predicted: \"5\", Actual: \"3\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"1\", Actual: \"6\"\n",
            "Predicted: \"2\", Actual: \"8\"\n",
            "Predicted: \"4\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"8\", Actual: \"3\"\n",
            "Predicted: \"8\", Actual: \"4\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"5\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"6\", Actual: \"5\"\n",
            "Predicted: \"7\", Actual: \"2\"\n",
            "Predicted: \"0\", Actual: \"6\"\n",
            "Predicted: \"3\", Actual: \"2\"\n",
            "Predicted: \"5\", Actual: \"8\"\n",
            "Predicted: \"9\", Actual: \"4\"\n",
            "Predicted: \"4\", Actual: \"6\"\n",
            "Tests:9531/10000 OK\n"
          ]
        }
      ],
      "source": [
        "# Perform a Quick Test on the Test Dataset\n",
        "\n",
        "model.eval()\n",
        "fail = 0\n",
        "\n",
        "print(\"Test Data Len: \" + str(len(test_data)))\n",
        "\n",
        "for x, y in test_data:\n",
        "  with torch.no_grad():\n",
        "      x = x.to(device)\n",
        "      pred = model(x)\n",
        "      predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "      if(predicted != actual):\n",
        "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "        fail += 1\n",
        "\n",
        "print(\"Tests:\" + str(len(test_data) - fail) + \"/\" + str(len(test_data)) + \" OK\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
